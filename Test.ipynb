{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Results (Tables 1 & 2 & 3 in Paper)\n",
    "\n",
    "- **Pretrained Single_Velocity_HPT**  \n",
    "   Reported by *Kong et al. (2021)*, uses the AMT-estimated MIDI notes for evaluation.  \n",
    "   → This reflects the performance of **original Automatic Music Transcription (AMT)** systems.\n",
    "\n",
    "- **Retrained Single_Velocity_HPT**  \n",
    "   Uses the **ground-truth MIDI notes** for evaluation.  \n",
    "   → This simulates a use case where **the MIDI transcription timing has already been corrected** (either manually or via audio–MIDI alignment tools).\n",
    "\n",
    "- **Dual_Velocity_HPT** and **Triple_Velocity_HPT**  \n",
    "   Follow the same setup as the retrained Single_Velocity_HPT, and the goal is to **refine MIDI velocity prediction** based on known note timings.\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "Please check the results on this link (available_later_for_anonymous). Our code will automatically upload all evaluation results to wandb logger, which is forming this online report. The following code is for a single inference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Evaluation Mode : Kim et al.\n",
      "Model Name      : FiLMUNetPretrained+frame\n",
      "Test Set        : smd\n",
      "================================================================================\n",
      "Kim Eval: 100%|███████████████| 49/49 [09:30<00:00, 11.64s/file, frame_err=9.96]\n",
      "\n",
      "===== Kim-style Average Metrics =====\n",
      "frame_max_error: 9.9590\n",
      "frame_max_std: 8.3273\n",
      "f1_score: 0.5935\n",
      "precision: 0.5944\n",
      "recall: 0.8877\n",
      "onset_masked_error: 16.0383\n",
      "onset_masked_std: 12.4601\n"
     ]
    }
   ],
   "source": [
    "!python pytorch/calculate_scores.py exp.batch_size=30 \\\n",
    "  model.name=\"FiLMUNetPretrained\" model.input2=\"frame\" exp.ckpt_iteration=1000000 \\\n",
    "  dataset.test_set=smd \\\n",
    "  feature.audio_feature=logmel feature.sample_rate=16000 feature.segment_seconds=2.0 feature.hop_seconds=1.0 feature.frames_per_second=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/datadisk/home/22828187/conda_env/miniconda3/envs/bark_env/lib/python3.10/site-packages/nnAudio/Spectrogram.py:4: Warning: importing Spectrogram subpackage will be deprecated soon. You should import the feature extractor from the feature subpackage. See actual documentation.\n",
      "  warnings.warn(\n",
      "================================================================================\n",
      "Inference Mode : DATASET (single checkpoint)\n",
      "Model Name     : FiLMUNetPretrained+frame\n",
      "Test Set       : smd\n",
      "Using Device   : cuda\n",
      "Feature Config : logmel | sr=16000 | fps=100 | seg=2.0s\n",
      "Checkpoint     : /media/datadisk/home/22828187/zhanh/202510_hpt_data/workspaces/checkpoints/FiLMUNetPretrained+frame/1000000_iterations.pth\n",
      "================================================================================\n",
      "Proc 1000000 Ckpt: 100%|██████████████████████| 49/49 [07:29<00:00,  9.17s/file]\n",
      "\n",
      "[Done] Dataset inference finished in 449.41 sec\n"
     ]
    }
   ],
   "source": [
    "!python pytorch/inference.py \\\n",
    "  --mode dataset \\\n",
    "  --velocity-method max_frame \\\n",
    "  --overrides \\\n",
    "    model.name=FiLMUNetPretrained model.input2=frame \\\n",
    "    dataset.test_set=smd exp.ckpt_iteration=1000000 \\\n",
    "    feature.sample_rate=16000 feature.segment_seconds=2.0 feature.hop_seconds=1.0 \\\n",
    "    feature.audio_feature=logmel feature.frames_per_second=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/datadisk/home/22828187/conda_env/miniconda3/envs/bark_env/lib/python3.10/site-packages/nnAudio/Spectrogram.py:4: Warning: importing Spectrogram subpackage will be deprecated soon. You should import the feature extractor from the feature subpackage. See actual documentation.\n",
      "  warnings.warn(\n",
      "================================================================================\n",
      "Inference Mode : DATASET_SCORE (single checkpoint)\n",
      "Model Name     : FiLMUNetPretrained+frame\n",
      "Test Set       : smd\n",
      "Using Device   : cuda\n",
      "Feature Config : logmel | sr=16000 | fps=100 | seg=2.0s\n",
      "Checkpoint     : /media/datadisk/home/22828187/zhanh/202510_hpt_data/workspaces/checkpoints/FiLMUNetPretrained+frame/1000000_iterations.pth\n",
      "MIDI Output    : /media/datadisk/home/22828187/zhanh/202510_hpt_data/workspaces/dataset_score/smd/FiLMUNetPretrained+frame/1000000_iterations/midis\n",
      "Results Dir    : /media/datadisk/home/22828187/zhanh/202510_hpt_data/workspaces/dataset_score/smd/FiLMUNetPretrained+frame/1000000_iterations\n",
      "================================================================================\n",
      "Dataset Score: 100%|█████████| 49/49 [13:55<00:00, 17.05s/file, frame_err=10.00]\n",
      "\n",
      "===== Dataset Score (velocity-picked) Averages =====\n",
      "frame_max_error: 10.0024\n",
      "frame_max_std: 8.2800\n",
      "f1_score: 0.8426\n",
      "precision: 0.9868\n",
      "recall: 0.7838\n",
      "frame_mask_f1: 0.3493\n",
      "frame_mask_precision: 0.5000\n",
      "frame_mask_recall: 0.2838\n",
      "onset_masked_error: 10.1006\n",
      "onset_masked_std: 8.3790\n"
     ]
    }
   ],
   "source": [
    "!python pytorch/inference.py \\\n",
    "  --mode dataset_velo_score \\\n",
    "  --velocity-method max_frame \\\n",
    "  --overrides \\\n",
    "    model.name=FiLMUNetPretrained model.input2=frame \\\n",
    "    dataset.test_set=smd exp.ckpt_iteration=1000000 \\\n",
    "    feature.sample_rate=16000 feature.segment_seconds=2.0 feature.hop_seconds=1.0 \\\n",
    "    feature.audio_feature=logmel feature.frames_per_second=100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python pytorch/inference.py \\\n",
    "  --mode dataset_audio_score \\\n",
    "  --velocity-method max_frame \\\n",
    "  --soundfont-path /path/to/FluidR3_GM.sf2 \\\n",
    "  --overrides model.name=FiLMUNetPretrained model.input2=frame \\\n",
    "             dataset.test_set=smd exp.ckpt_iteration=1000000 \\\n",
    "             feature.sample_rate=16000 feature.segment_seconds=2.0 \\\n",
    "             feature.hop_seconds=1.0 feature.audio_feature=logmel \\\n",
    "             feature.frames_per_second=100 \\\n",
    "  --audio-eval-sample-rate 44100 \\\n",
    "  --audio-eval-frames-per-second 86 \\\n",
    "  --audio-eval-fft-size 1024\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/datadisk/home/22828187/conda_env/miniconda3/envs/bark_env/lib/python3.10/site-packages/nnAudio/Spectrogram.py:4: Warning: importing Spectrogram subpackage will be deprecated soon. You should import the feature extractor from the feature subpackage. See actual documentation.\n",
      "  warnings.warn(\n",
      "================================================================================\n",
      "Evaluation Mode : Kim et al.\n",
      "Model Name      : FiLMUNetPretrained+frame\n",
      "Test Set        : smd\n",
      "================================================================================\n",
      "Kim Eval: 100%|███████████████| 49/49 [09:01<00:00, 11.06s/file, frame_err=9.96]\n",
      "\n",
      "===== Kim-style Average Metrics =====\n",
      "frame_max_error: 9.9590\n",
      "frame_max_std: 8.3273\n",
      "f1_score: 0.5935\n",
      "precision: 0.5944\n",
      "recall: 0.8877\n",
      "frame_mask_f1: 0.9694\n",
      "frame_mask_precision: 0.9694\n",
      "frame_mask_recall: 0.9694\n",
      "onset_masked_error: 16.0383\n",
      "onset_masked_std: 12.4601\n"
     ]
    }
   ],
   "source": [
    "!python pytorch/calculate_scores.py \\\n",
    "  model.name=\"FiLMUNetPretrained\" model.input2=\"frame\" exp.ckpt_iteration=1000000 \\\n",
    "  dataset.test_set=smd \\\n",
    "  feature.sample_rate=16000 feature.segment_seconds=2.0 feature.hop_seconds=1.0 \\\n",
    "  feature.audio_feature=logmel feature.frames_per_second=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Evaluation Mode : SINGLE\n",
      "Model Name      : FiLMUNetPretrained+frame\n",
      "Test Set        : smd\n",
      "Using device    : cpu\n",
      "================================================================================\n",
      "Checkpoint      : 1100000_iterations.pth\n",
      "\n",
      "[Done] Score Calculation Time: 11.99 sec\n",
      "\n",
      "===== FiLMUNetPretrained+frame, iter=1100000 =====\n",
      "velocity_mae: 15.6400\n",
      "velocity_std: 12.3622\n",
      "velocity_recall: 0.5247\n"
     ]
    }
   ],
   "source": [
    "!python pytorch/inference.py \\\n",
    "  exp.run_infer=\"multi\" model.type=\"velo\" \\\n",
    "  model.name=\"DynestAudioCNN\" \\\n",
    "  dataset.test_set=\"smd\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Evaluation Mode : SINGLE\n",
      "Model Name      : FiLMUNetPretrained+frame\n",
      "Test Set        : smd\n",
      "Using device    : cpu\n",
      "================================================================================\n",
      "Checkpoint      : 1000000_iterations.pth\n",
      "\n",
      "[Done] Score Calculation Time: 14.13 sec\n",
      "\n",
      "===== FiLMUNetPretrained+frame, iter=1000000 =====\n",
      "velocity_mae: 16.0383\n",
      "velocity_std: 12.4601\n",
      "velocity_recall: 0.5262\n"
     ]
    }
   ],
   "source": [
    "!python pytorch/calculate_scores.py exp.run_infer='single' model.type='velo' exp.ckpt_iteration=1000000\\\n",
    "     model.name='FiLMUNetPretrained' model.input2='frame'\\\n",
    "     dataset.test_set='smd' exp.num_workers=12 # maps, maestro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Evaluation Mode : MULTI\n",
      "Model Name      : DynestAudioCNN\n",
      "Test Set        : smd\n",
      "Using device    : cpu\n",
      "================================================================================\n",
      "Found 1 checkpoints in /media/datadisk/home/22828187/zhanh/202510_hpt_data/workspaces/checkpoints/DynestAudioCNN\n",
      "------------------------------------------------------------\n",
      "[1/1] Evaluating: 0_iterations.pth\n",
      "[Done] Time: 15.19 sec\n",
      "velocity_mae: 15.3810\n",
      "velocity_std: 10.4575\n",
      "velocity_recall: 0.3875\n",
      "\n",
      "[Saved] Summary in Wandb and CSV: /media/datadisk/home/22828187/zhanh/202510_hpt_data/workspaces/logs/DynestAudioCNN_smd.csv\n",
      "================================================================================\n",
      "All checkpoint scores completed.\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# !python pytorch/calculate_scores.py exp.run_infer='multi' exp.num_workers=12 model.type='velo'\\\n",
    "#   model.name='FiLMUNetPretrained' model.input2=\"frame\" \\\n",
    "#   dataset.test_set='smd' # maps, maestro\n",
    "\n",
    "# !python pytorch/calculate_scores.py exp.run_infer='single' model.type='velo' exp.ckpt_iteration=1100000\\\n",
    "#      model.name='FiLMUNetPretrained' model.input2='frame'\\\n",
    "#      dataset.test_set='smd' exp.num_workers=12 # maps, maestro\n",
    "\n",
    "!python pytorch/calculate_scores.py exp.run_infer='multi' exp.num_workers=12 model.type='velo'\\\n",
    "  model.name='DynestAudioCNN'\\\n",
    "  dataset.test_set='smd' # maps, maestro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Inference Mode : SINGLE\n",
      "Model Name     : FiLMUNetPretrained+frame\n",
      "Test Set       : smd\n",
      "Using Device   : cuda\n",
      "================================================================================\n",
      "Checkpoint     : 1000000_iterations.pth\n",
      "Proc 1000000 Ckpt: 100%|██████████████████████| 49/49 [07:53<00:00,  9.67s/file]\n",
      "\n",
      "[Done] Inference time: 474.09 sec\n"
     ]
    }
   ],
   "source": [
    "!python pytorch/inference.py  model.type='velo'\\\n",
    "    exp.run_infer='single' exp.ckpt_iteration=1000000\\\n",
    "    model.name='FiLMUNetPretrained' model.input2='frame'\\\n",
    "    dataset.test_set='smd'\\\n",
    "    feature.sample_rate=16000 \\\n",
    "    feature.segment_seconds=2.0 \\\n",
    "    feature.hop_seconds=1.0 \\\n",
    "    feature.frames_per_second=100 \\\n",
    "    feature.audio_feature=\"logmel\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Evaluation Mode : Kim-style (frame-level)\n",
      "Model Name      : FiLMUNetPretrained+frame\n",
      "Test Set        : smd\n",
      "================================================================================\n",
      "Kim-style scoring: 100%|█████| 49/49 [01:08<00:00,  1.40s/file, frame_err=18.56]\n",
      "\n",
      "===== Kim-style Average Metrics =====\n",
      "frame_max_error: 16.0383\n",
      "std_max_error: 12.4601\n",
      "average_precision_score: 0.1888\n",
      "f1_score: 0.3170\n",
      "precision_score: 0.1888\n",
      "recall_score: 1.0000\n",
      "frame_precision: 0.1888\n",
      "frame_recall: 1.0000\n",
      "frame_f1: 0.3170\n",
      "onset_mean_error: 16.0383\n",
      "onset_std_error: 12.4601\n"
     ]
    }
   ],
   "source": [
    "!python pytorch/calculate_scores.py exp.num_workers=12 model.type='velo'\\\n",
    "  exp.run_infer='single' exp.ckpt_iteration=1000000 \\\n",
    "  model.name='FiLMUNetPretrained' model.input2='frame'\\\n",
    "  dataset.test_set='smd'\\\n",
    "  feature.sample_rate=16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Evaluation Mode : Kim et al.\n",
      "Model Name      : Dual_Velocity_HPT+onset\n",
      "Test Set        : smd\n",
      "================================================================================\n",
      "Kim Eval: 100%|██████████████| 49/49 [08:42<00:00, 10.67s/file, frame_err=16.07]\n",
      "\n",
      "===== Kim-style Average Metrics =====\n",
      "frame_max_error: 16.0671\n",
      "frame_max_std: 8.9057\n",
      "f1_score: 0.0470\n",
      "precision: 0.0249\n",
      "recall: 0.5000\n",
      "frame_mask_f1: 1.0000\n",
      "frame_mask_precision: 1.0000\n",
      "frame_mask_recall: 1.0000\n",
      "onset_masked_error: 9.8807\n",
      "onset_masked_std: 6.9940\n"
     ]
    }
   ],
   "source": [
    "!python pytorch/calculate_scores.py \\\n",
    "  exp.batch_size=12 \\\n",
    "  model.name=\"Dual_Velocity_HPT\" \\\n",
    "  exp.ckpt_iteration=18000 \\\n",
    "  model.input2=onset \\\n",
    "  dataset.test_set=smd \\\n",
    "  feature.audio_feature=logmel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Inference Mode : MULTI\n",
      "Model Name     : Single_Velocity_HPT\n",
      "Test Set       : smd\n",
      "Using Device   : cuda\n",
      "================================================================================\n",
      "Found 2 checkpoints in ./workspaces/checkpoints/Single_Velocity_HPT\n",
      "------------------------------------------------------------\n",
      "[1/2] 195000_iteration.pth\n",
      "Proc 195000 Ckpt: 100%|███████████████████████| 49/49 [06:25<00:00,  7.87s/file]\n",
      "[Done] Time: 385.84 sec\n",
      "------------------------------------------------------------\n",
      "[2/2] 200000_iteration.pth\n",
      "Proc 200000 Ckpt: 100%|███████████████████████| 49/49 [06:28<00:00,  7.93s/file]\n",
      "[Done] Time: 388.63 sec\n",
      "\n",
      "================================================================================\n",
      "All checkpoint inference completed in 774.47 sec\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "!python pytorch/inference.py exp.run_infer='multi' model.type='velo'\\\n",
    "     model.name='Single_Velocity_HPT'\\\n",
    "     dataset.test_set='smd' # maps, maestro\n",
    "\n",
    "# !python pytorch/inference.py exp.run_infer='multi' model.type='velo'\\\n",
    "#      model.name='Dual_Velocity_HPT' model.input2='onset'\\\n",
    "#      dataset.test_set='smd' # maps, maestro\n",
    "\n",
    "# !python pytorch/inference.py exp.run_infer='multi' model.type='velo'\\\n",
    "#      model.name='Triple_Velocity_HPT' model.input2='onset' model.input3='exframe'\\\n",
    "#      dataset.test_set='smd' # maps, maestro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Evaluation Mode : MULTI\n",
      "Model Name      : Single_Velocity_HPT\n",
      "Test Set        : smd\n",
      "Using device    : cpu\n",
      "================================================================================\n",
      "Found 2 checkpoints in ./workspaces/checkpoints/Single_Velocity_HPT\n",
      "------------------------------------------------------------\n",
      "[1/2] Evaluating: 195000_iteration.pth\n",
      "[Done] Time: 36.30 sec\n",
      "velocity_mae: 14.8968\n",
      "velocity_std: 8.6206\n",
      "velocity_recall: 0.7515\n",
      "------------------------------------------------------------\n",
      "[2/2] Evaluating: 200000_iteration.pth\n",
      "[Done] Time: 41.78 sec\n",
      "velocity_mae: 15.3933\n",
      "velocity_std: 8.7335\n",
      "velocity_recall: 0.7493\n",
      "\n",
      "[Saved] Summary in Wandb and CSV: ./workspaces/logs/Single_Velocity_HPT_smd.csv\n",
      "================================================================================\n",
      "All checkpoint scores completed.\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "!python pytorch/calculate_scores.py exp.run_infer='multi' exp.num_workers=12 model.type='velo'\\\n",
    "     model.name='Single_Velocity_HPT'\\\n",
    "     dataset.test_set='smd' # maps, maestro\n",
    "\n",
    "# !python pytorch/calculate_scores.py exp.run_infer='multi' exp.num_workers=12 model.type='velo'\\\n",
    "#      model.name='Dual_Velocity_HPT' model.input2='onset'\\\n",
    "#      dataset.test_set='smd' # maps, maestro\n",
    "\n",
    "# !python pytorch/calculate_scores.py exp.run_infer='multi' exp.num_workers=12 model.type='velo'\\\n",
    "#      model.name='Triple_Velocity_HPT' model.input2='onset' model.input3='exframe'\\\n",
    "#      dataset.test_set='smd' # maps, maestro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We conducted inferences on Cloud GPUs with the following code. Therefore, no results recorded in this jupyter notebook. You can find our results via [wandb report](https://api.wandb.ai/links/zhanh-uwa/wc7q3j5b)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_CONFIGS=(\n",
    "    \"model.name='Single_Velocity_HPT'\"\n",
    "    \"model.name='Dual_Velocity_HPT' model.input2='onset'\"\n",
    "    \"model.name='Dual_Velocity_HPT' model.input2='frame'\"\n",
    "    \"model.name='Dual_Velocity_HPT' model.input2='exframe'\"\n",
    "    \"model.name='Triple_Velocity_HPT' model.input2='onset' model.input3='frame'\"\n",
    "    \"model.name='Triple_Velocity_HPT' model.input2='onset' model.input3='exframe'\"\n",
    "    \"model.name='Triple_Velocity_HPT' model.input2='frame' model.input3='exframe'\"\n",
    ")\n",
    "\n",
    "DATASET='maps' # 'smd', 'maps', or 'maestro'\n",
    "\n",
    "# Get the specific config based on SLURM_ARRAY_TASK_ID\n",
    "CONFIG=${MODEL_CONFIGS[$SLURM_ARRAY_TASK_ID]}\n",
    "\n",
    "echo \"Selected model config index: $SLURM_ARRAY_TASK_ID\"\n",
    "echo \"Running inference with config: $CONFIG\"\n",
    "python pytorch/inference.py exp.run_infer='multi' model.type='velo' $CONFIG dataset.test_set=\"$DATASET\"\n",
    "\n",
    "echo \"Running scoring with config: $CONFIG\"\n",
    "python pytorch/calculate_scores.py exp.run_infer='multi' exp.num_workers=12 model.type='velo' $CONFIG dataset.test_set=\"$DATASET\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bark_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
